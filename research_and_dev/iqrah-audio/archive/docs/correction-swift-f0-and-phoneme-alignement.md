Great progress. Here’s the blunt read:

## 1) SwiftF0 pitch extraction — close, but a few fixes explain your “noisier than CREPE” result

What’s good:

* 16 kHz mono + direct `detect_from_array()` ✅
* Using detector’s own timestamps ✅
* Range-guarding (50–500 Hz) ✅

What’s likely hurting you vs CREPE:

* You don’t gate by **confidence** (only by range).
* No **post-smoothing** (CREPE’s classic TF impl tends to look steadier).
* Fixed 50–500 Hz mask can kill valid frames (adult males often sit 80–220 Hz; some reciters dip < 70 Hz on endings).
* `duration=float(time[-1])` can under-report; use `len(audio)/sr`.

**Quick fixes (minimal change):**

* Gate by **voicing & confidence** (e.g., `>=0.6`) before the range mask.
* Add a tiny **median** then **Savitzky–Golay** smoother on voiced frames.
* Make fmin/fmax **profile-aware** (male default: 65–420; female: 110–600) or auto-infer from the median F0 of the first second.
* Fill micro-gaps (<30 ms) by linear interp to avoid flicker in your UI.

```python
v = (voiced.astype(bool)) & (confidence >= 0.6)
f0 = f0_hz.copy()
f0[~v] = 0.0

# range clamp AFTER confidence gating
rng = (f0 >= 55) & (f0 <= 550)
f0[~rng] = 0.0

# light smoothing on voiced frames
idx = np.where(f0 > 0)[0]
if idx.size:
    from scipy.signal import medfilt, savgol_filter
    f = f0[idx]
    f = medfilt(f, kernel_size=3)
    if f.size >= 7:
        f = savgol_filter(f, window_length=7, polyorder=2)
    f0[idx] = f

# small gap fill (<3 frames @10ms)
z = np.where(f0==0)[0]
# ... (optional: interpolate short runs)
```

Also set `duration = len(audio)/actual_sr`.
Do those three and SwiftF0 should look at least as clean as CREPE on solo recitation. If it still isn’t, run **CREPE (torchcrepe)** as a second extractor and pick per-segment the track with fewer octave flips and lower jitter on madd vowels.

---

## 2) Phoneme alignment — structurally right, but two blockers

You fixed the big stuff (uroman → MMS-FA, ratio time conversion, word-windowing, Tajwīd from Arabic). Two issues remain:

### A) You still split IPA **by characters**

You commented “PanPhon” but don’t use it. Single-codepoint cuts will break multichar phones and combining diacritics. Replace `text_to_ipa_phones()` with PanPhon:

```python
import panphon.segment as pseg

def text_to_ipa_phones(arabic_text: str) -> List[str]:
    ipa = _get_epitran().transliterate(arabic_text)
    return pseg.IPA().seg_list(ipa)  # true phones
```

### B) Duration apportion is too naive (uniform)

Uniformly slicing total char duration across all phones ignores where time actually went. Use **per-char durations** as bins, then split each bin across the phones generated by that **grapheme**. Minimal pragmatic scheme:

1. Keep **romanized_no_spaces** and its char spans from MMS-FA.
2. Build a **grapheme→roman** map (indices) by stripping spaces from the Arabic and romanized forms in lock-step (you can also align with a simple monotonic DP).
3. For each Arabic grapheme:

   * Get its **char-span duration** from the aligned roman chars.
   * Convert that grapheme to **phones** (Epitran+PanPhon).
   * **Distribute that one char-bin duration** across its phones (equal or weighted by simple heuristics: longer vowel symbols get more).

That keeps phone times faithful to where MMS says the audio energy matched.

Tiny sketch for step 3 replacement:

```python
def distribute_by_grapheme(char_spans, arabic_text, ipa_phones_per_grapheme):
    phone_spans = []
    t = char_spans[0]['start'] if char_spans else 0.0
    for g_idx, phones in enumerate(ipa_phones_per_grapheme):
        # sum durations of roman chars mapped to this grapheme
        dur = sum(cs['duration'] for cs in char_spans if cs['g_idx']==g_idx)
        if dur <= 0 or not phones: 
            continue
        # simple split (or weight vowels a bit more)
        splits = [dur/len(phones)]*len(phones)
        for ph, d in zip(phones, splits):
            phone_spans.append({'phoneme': ph, 'start': t, 'end': t+d, 'duration': d})
            t += d
    return phone_spans
```

(You’d populate `g_idx` on each `char_span` when you build the grapheme↔roman map.)

### Other small wins

* **Filter non-letters** from `labels` (skip blanks or specials).
* After Tajwīd duration edits, **re-normalize** to keep segments contiguous and clipped to `[word_start, word_end]`.
* Keep half-open intervals `[start, end)` everywhere (you already do this in `map_phonemes_to_pitch`—good).
* If you later want posterior-weighted splits: grab the emission slice for the roman chars feeding a grapheme and allocate by the sum of their posteriors.

---

### TL;DR

* **SwiftF0**: add confidence gating + light smoothing + better range handling; compute duration from samples. That’s why CREPE “looked cleaner.”
* **Alignment**: actually use **PanPhon** for phones and split durations **per grapheme** instead of uniform global slicing. With those two changes, your pipeline is production-ready for a first pass.
